{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RODDA Ocean Application SANI\n",
    "Imperial College London - CMCC\n",
    "Authors: César Quilodrán-Casas and Marco Stefanelli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import netCDF4\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_noDA = '/data/c-quilo/CMCC/NoDA/SHYFEM_NO_ASSIM/'\n",
    "directory_DA = '/data/c-quilo/CMCC/DA/SHYFEM_ASSIM_BIVARIATE/'\n",
    "list_of_paths_noDA = sorted(glob.glob(directory_noDA + '/*'))\n",
    "list_of_paths_DA = sorted(glob.glob(directory_DA + '/*'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_noDA = np.zeros((365*24, 90351))\n",
    "count = 0\n",
    "for file in list_of_paths_noDA:\n",
    "    data_noDA = xr.open_dataset(file)\n",
    "    sst_noDA[24*count:24*(count+1), :] = data_noDA.temperature\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_DA = np.zeros((365*24, 90351))\n",
    "count = 0\n",
    "for file in list_of_paths_DA:\n",
    "    data_DA = xr.open_dataset(file)\n",
    "    sst_DA[24*count:24*(count+1)] = data_DA.temperature\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 90351)\n"
     ]
    }
   ],
   "source": [
    "print(sst_noDA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 90351)]           0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               46260224  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 90351)             46350063  \n",
      "=================================================================\n",
      "Total params: 92,945,775\n",
      "Trainable params: 92,942,447\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nFeatures = sst_noDA.shape[1]\n",
    "encoder_inputs = keras.Input(shape=nFeatures)\n",
    "alpha = 0.3\n",
    "\n",
    "enc = keras.layers.Dense(512)(encoder_inputs)\n",
    "enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "enc = keras.layers.Dropout(0.5)(enc)\n",
    "enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "enc = keras.layers.Dense(256)(enc)\n",
    "enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "enc = keras.layers.Dropout(0.5)(enc)\n",
    "enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "enc = keras.layers.Dense(128)(enc)\n",
    "enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "enc = keras.layers.Dropout(0.5)(enc)\n",
    "enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "enc = keras.layers.Dense(256)(enc)\n",
    "enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "enc = keras.layers.Dropout(0.5)(enc)\n",
    "enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "enc = keras.layers.Dense(512)(enc)\n",
    "enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "enc = keras.layers.Dropout(0.5)(enc)\n",
    "enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "output = keras.layers.Dense(nFeatures)(enc)\n",
    "#enc = keras.layers.LeakyReLU(alpha)(enc)\n",
    "#enc = keras.layers.Dropout(0.5)(enc)\n",
    "#enc = keras.layers.BatchNormalization()(enc)\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, output, name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = sst_noDA.shape[0]\n",
    "indices = np.arange(n_samples)\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(sst_noDA, sst_DA, indices, test_size = 0.2, random_state = 42, shuffle=True)\n",
    "encoder.compile(loss='mse', optimizer=tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 15s 542ms/step - loss: 9.2758 - val_loss: 19.4843\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 14s 513ms/step - loss: 9.1270 - val_loss: 20.0743\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 15s 531ms/step - loss: 8.6886 - val_loss: 12.9705\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 15s 531ms/step - loss: 8.1774 - val_loss: 6.6388\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 14s 517ms/step - loss: 8.0034 - val_loss: 5.5865\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 15s 534ms/step - loss: 7.5086 - val_loss: 4.3489\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 15s 525ms/step - loss: 7.2364 - val_loss: 3.5661\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 15s 538ms/step - loss: 7.3149 - val_loss: 4.2257\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 15s 537ms/step - loss: 7.2414 - val_loss: 3.3500\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 15s 538ms/step - loss: 7.1055 - val_loss: 6.3630\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 15s 539ms/step - loss: 6.6772 - val_loss: 4.1041\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 15s 525ms/step - loss: 6.3598 - val_loss: 2.7273\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 15s 522ms/step - loss: 6.3400 - val_loss: 3.3894\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 15s 545ms/step - loss: 6.0998 - val_loss: 2.6516\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 16s 558ms/step - loss: 5.8266 - val_loss: 3.9958\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 15s 550ms/step - loss: 5.7150 - val_loss: 8.3684\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 15s 549ms/step - loss: 5.8416 - val_loss: 7.0594\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 15s 531ms/step - loss: 5.6851 - val_loss: 6.5450\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 15s 526ms/step - loss: 5.6218 - val_loss: 4.3436\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 15s 522ms/step - loss: 5.4913 - val_loss: 4.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0d855e940>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(X_train, y_train, validation_data = (X_test, y_test), epochs=200, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data/c-quilo/CMCC/RODDA_SANI.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bese-datalearning.ese.ic.ac.uk/data/c-quilo/CMCC/RODDA_SANI.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m lon \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(directory_DA \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/sst_saniv1_chunk_0120.nos.nc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bese-datalearning.ese.ic.ac.uk/data/c-quilo/CMCC/RODDA_SANI.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m index \u001b[39m=\u001b[39m indices_test[\u001b[39m42\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bese-datalearning.ese.ic.ac.uk/data/c-quilo/CMCC/RODDA_SANI.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mtricontourf(lon, lat, sst_DA[index, :], cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjet\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lat' is not defined"
     ]
    }
   ],
   "source": [
    "#Predict DA result\n",
    "#Read .nc\n",
    "lon = xr.open_dataset(directory_DA + '/sst_saniv1_chunk_0120.nos.nc').lon\n",
    "lon =\n",
    "index = indices_test[42]\n",
    "plt.tricontourf(lon, lat, sst_DA[index, :], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04c326ab39f7cdc473ebc7acaec36b3cfd9f692ecff7c7f99b1c8c609feb2993"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
